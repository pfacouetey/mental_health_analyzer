{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3060b6fb",
      "metadata": {
        "id": "3060b6fb"
      },
      "source": [
        "# Mental-Health Text Classification: Inference On New Data\n",
        "\n",
        "This notebook is designed to demonstrate how to use the previously trained models of the notebook `train_deep_learning_models.ipynb` for inference on new posts/comments.\n",
        "\n",
        "Main Goals of this notebook :\n",
        "- Load all trained models directly from the Hugging Face Hub.\n",
        "- Set up a quick inference pipeline to make predictions on new text data.\n",
        "- Give a link of a deployed Huggig Face App performing online same task as the one done here.\n",
        "\n",
        "This notebook is organized as follows:\n",
        "\n",
        "1.  **Packages Loading**: Load necessary packages.\n",
        "2.  **Models Loading**: Load all three models.\n",
        "3.  **Inference Pipeline Setup**: Prepare the inference pipeline used for making predictions on new posts/comments locally.\n",
        "4.  **Infer on New Data**: Infer locally mental health state of a person based on its posts/comments.\n",
        "5.  **Deployed Gradio App**: The link of deployed App on a Hugging Face link with the best trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "603ee0d0",
      "metadata": {
        "id": "603ee0d0"
      },
      "source": [
        "### **1. Packages Loading**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7cc28ff7",
      "metadata": {
        "id": "7cc28ff7"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4ca7516",
      "metadata": {
        "id": "e4ca7516"
      },
      "source": [
        "### **2. Models Loading**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b9dea389",
      "metadata": {
        "id": "b9dea389"
      },
      "outputs": [],
      "source": [
        "REPO_ID_ROBERTA = \"paragonadey/mh-text-classifier-roberta-base\"\n",
        "REPO_ID_DEBERTA = \"paragonadey/mh-text-classifier-deberta-v3-base_v2\"\n",
        "REPO_ID_MODERBERT = \"paragonadey/mh-text-classifier-moderbert-large_v2\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d-PdlTrrMaN0",
      "metadata": {
        "id": "d-PdlTrrMaN0"
      },
      "source": [
        "### **3. Inference Pipeline Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9cfG71SmMZnN",
      "metadata": {
        "id": "9cfG71SmMZnN"
      },
      "outputs": [],
      "source": [
        "def create_inference_pipeline(repo_id):\n",
        "    \"\"\"\n",
        "    Creates an inference pipeline for a given model repository ID.\n",
        "\n",
        "    Args:\n",
        "        repo_id (str): The repository ID of the model on Hugging Face Hub.\n",
        "\n",
        "    Returns:\n",
        "        pipeline: The Hugging Face inference pipeline.\n",
        "    \"\"\"\n",
        "    # Create the pipeline specifying the task, model, and tokenizer.\n",
        "    text_classifier = pipeline(\n",
        "        \"text-classification\",\n",
        "        model=repo_id,\n",
        "        tokenizer=repo_id,\n",
        "    )\n",
        "\n",
        "    # id2label needs to be passed to the pipeline to map the output logits to labels\n",
        "    # Its format is already known from the work done in the notebook `train_deep_learning_models.ipynb`\n",
        "    id2label = {\n",
        "        0: 'EDAnonymous',\n",
        "        1: 'addiction',\n",
        "        2: 'adhd',\n",
        "        3: 'alcoholism',\n",
        "        4: 'anxiety',\n",
        "        5: 'autism',\n",
        "        6: 'bipolarreddit',\n",
        "        7: 'bpd',\n",
        "        8: 'depression',\n",
        "        9: 'healthanxiety',\n",
        "        10: 'lonely',\n",
        "        11: 'normal',\n",
        "        12: 'ptsd',\n",
        "        13: 'schizophrenia',\n",
        "        14: 'socialanxiety',\n",
        "        15: 'suicidewatch'\n",
        "    }\n",
        "\n",
        "    # Manually set the id2label mapping on the pipeline's model config\n",
        "    # This ensures the pipeline uses the correct labels for output\n",
        "    if hasattr(text_classifier.model.config, 'id2label'):\n",
        "         text_classifier.model.config.id2label = id2label\n",
        "    elif hasattr(text_classifier.model.config, 'label2id'):\n",
        "        text_classifier.model.config.id2label = {v: k for k, v in text_classifier.model.config.label2id.items()}\n",
        "\n",
        "        text_classifier.model.config.id2label.update(id2label)\n",
        "    else:\n",
        "        # If no id2label or label2id in config, set it directly\n",
        "         text_classifier.model.config.id2label = id2label\n",
        "\n",
        "    return text_classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gHUqKvJE8Iqp",
      "metadata": {
        "id": "gHUqKvJE8Iqp"
      },
      "source": [
        "### **4. Infer on New Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "X9psAMhW9clS",
      "metadata": {
        "id": "X9psAMhW9clS"
      },
      "outputs": [],
      "source": [
        "my_depression_sentence = \"I am feeling very down and have no motivation.\"\n",
        "my_suicide_sentence = \"Need to kill some people, then myself.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "PCXiF9CQM2Rm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCXiF9CQM2Rm",
        "outputId": "a03cc903-6a9a-483c-ba7b-357f66ee2330"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My Depression Sentence: I am feeling very down and have no motivation.\n",
            "RoBERTa Prediction On Depression Sentence: {'label': 'depression', 'score': 0.9756641387939453}\n",
            "----------------------------------------------------------------------\n",
            "My Suicide Sentence: Need to kill some people, then myself.\n",
            "RoBERTa Prediction On Depression Sentence: {'label': 'suicidewatch', 'score': 0.686688244342804}\n"
          ]
        }
      ],
      "source": [
        "roberta_classifier = create_inference_pipeline(REPO_ID_ROBERTA)\n",
        "\n",
        "print(f\"My Depression Sentence: {my_depression_sentence}\")\n",
        "print(f\"RoBERTa Prediction On Depression Sentence: {roberta_classifier(my_depression_sentence)[0]}\")\n",
        "\n",
        "print(10*'-------')\n",
        "\n",
        "print(f\"My Suicide Sentence: {my_suicide_sentence}\")\n",
        "print(f\"RoBERTa Prediction On Depression Sentence: {roberta_classifier(my_suicide_sentence)[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fCJdCG4xNBZe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCJdCG4xNBZe",
        "outputId": "512805ee-c6dc-462d-a23f-4d99e2d7a17f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My Depression Sentence: I am feeling very down and have no motivation.\n",
            "DeBERTa Prediction On Depression Sentence: {'label': 'depression', 'score': 0.9577535390853882}\n",
            "----------------------------------------------------------------------\n",
            "My Suicide Sentence: Need to kill some people, then myself.\n",
            "DeBERTa Prediction On Depression Sentence: {'label': 'suicidewatch', 'score': 0.7814931273460388}\n"
          ]
        }
      ],
      "source": [
        "deberta_classifier = create_inference_pipeline(REPO_ID_DEBERTA)\n",
        "\n",
        "print(f\"My Depression Sentence: {my_depression_sentence}\")\n",
        "print(f\"DeBERTa Prediction On Depression Sentence: {deberta_classifier(my_depression_sentence)[0]}\")\n",
        "\n",
        "print(10*'-------')\n",
        "\n",
        "print(f\"My Suicide Sentence: {my_suicide_sentence}\")\n",
        "print(f\"DeBERTa Prediction On Depression Sentence: {deberta_classifier(my_suicide_sentence)[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "J80Z7EGANGc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J80Z7EGANGc0",
        "outputId": "b2985355-50bb-4948-8f57-e41f2ad2b51f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My Depression Sentence: I am feeling very down and have no motivation.\n",
            "ModerBERT Prediction On Depression Sentence: {'label': 'depression', 'score': 0.9607046842575073}\n",
            "----------------------------------------------------------------------\n",
            "My Suicide Sentence: Need to kill some people, then myself.\n",
            "ModerBERT Prediction On Depression Sentence: {'label': 'suicidewatch', 'score': 0.44293347001075745}\n"
          ]
        }
      ],
      "source": [
        "moderbert_classifier = create_inference_pipeline(REPO_ID_MODERBERT)\n",
        "\n",
        "print(f\"My Depression Sentence: {my_depression_sentence}\")\n",
        "print(f\"ModerBERT Prediction On Depression Sentence: {moderbert_classifier(my_depression_sentence)[0]}\")\n",
        "\n",
        "print(10*'-------')\n",
        "\n",
        "print(f\"My Suicide Sentence: {my_suicide_sentence}\")\n",
        "print(f\"ModerBERT Prediction On Depression Sentence: {moderbert_classifier(my_suicide_sentence)[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d57fc48",
      "metadata": {
        "id": "0d57fc48"
      },
      "source": [
        "### **5. Deployed Gradio App**\n",
        "\n",
        "- The best model `paragonadey/mh-text-classifier-roberta-base` was used to create a Gradio web application for inference.\n",
        "\n",
        "- You can try it out online here: [https://huggingface.co/spaces/paragonadey/mental-health-text-classifier](https://huggingface.co/spaces/paragonadey/mental-health-text-classifier)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
